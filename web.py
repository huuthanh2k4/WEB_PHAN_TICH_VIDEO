import os, time, tempfile, shutil
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import whisper
import joblib
from transformers.pipelines import pipeline
from yt_dlp import YoutubeDL
from NPL.tien_xu_ly import TienXuLy

# 0) UI t·ªëi thi·ªÉu ƒë·ªÉ health-check pass ngay
st.set_page_config(page_title="Subtitle & Emotion Analyzer", layout="wide")
st.title("üé¨ Ph√¢n t√≠ch ph·ª• ƒë·ªÅ & c·∫£m x√∫c t·ª´ video")

# --- 1) ƒê·ªãnh nghƒ©a cache resources, nh∆∞ng **kh√¥ng load** ngay ---
@st.cache_resource(show_spinner=False)
def get_whisper_model():
    return whisper.load_model("medium")

@st.cache_resource(show_spinner=False)
def get_translator(src_lang: str):
    return pipeline("translation", model=f"Helsinki-NLP/opus-mt-{src_lang}-en")

@st.cache_resource(show_spinner=False)
def get_tfidf():
    return joblib.load("Model ƒë√£ hu·∫•n luy·ªán/TF-IDF.sav")

@st.cache_resource(show_spinner=False)
def get_svc():
    return joblib.load("Model ƒë√£ hu·∫•n luy·ªán/svc_model.pkl")

processor = TienXuLy()

# --- 2) Input from user ---
st.sidebar.header("1. Ch·ªçn ngu·ªìn video")
mode = st.sidebar.radio("Ch·ªçn:", ("T·∫£i l√™n file", "Nh·∫≠p URL"))

video_path = None
if mode == "T·∫£i l√™n file":
    uploaded = st.sidebar.file_uploader("Upload video (.mp4/.mov/.avi)", type=["mp4","mov","avi"])
    if uploaded:
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tmp.write(uploaded.read()); tmp.close()
        video_path = tmp.name
elif mode == "Nh·∫≠p URL":
    url = st.sidebar.text_input("D√°n URL video (YouTube, TikTok, Vimeo‚Ä¶)")
    if url:
        # ch·ªâ hi·ªÉn th·ªã n√∫t download, nh∆∞ng kh√¥ng th·ª±c hi·ªán ngay
        pass

# 3) Khi ƒë·ªß input, hi·ªÉn th·ªã n√∫t x·ª≠ l√Ω
if (mode=="T·∫£i l√™n file" and video_path) or (mode=="Nh·∫≠p URL" and url):
    if st.button("‚ñ∂Ô∏è X·ª≠ l√Ω video"):
        # B·∫Øt ƒë·∫ßu ƒëo th·ªùi gian
        t0 = time.perf_counter()

        # 3.1) N·∫øu t·ª´ URL th√¨ download
        if mode == "Nh·∫≠p URL":
            try:
                with st.spinner("‚è≥ ƒêang t·∫£i video..."):
                    os.makedirs("temp_video", exist_ok=True)
                    ydl_opts = {
                        "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]",
                        "outtmpl": os.path.join("temp_video","%(id)s.%(ext)s"),
                        "merge_output_format":"mp4","quiet":True
                    }
                    with YoutubeDL(ydl_opts) as ydl:
                        info = ydl.extract_info(url, download=True)
                        video_path = ydl.prepare_filename(info)
                st.success(f"‚úîÔ∏è T·∫£i xong: {os.path.basename(video_path)}")
            except Exception as e:
                st.error(f"‚ùå T·∫£i video th·∫•t b·∫°i: {e}")
                st.stop()

        # 3.2) Load models (l·∫ßn ƒë·∫ßu s·∫Ω cache)
        whisper_model = get_whisper_model()
        tfidf_model    = get_tfidf()
        svc_model      = get_svc()

        # 4) Transcribe
        st.header("2. Transcription")
        with st.spinner("‚è≥ Whisper transcription..."):
            trans = whisper_model.transcribe(video_path)
        segments = trans["segments"]
        lang = trans["language"]
        st.write(f"üî§ Ng√¥n ng·ªØ ph√°t hi·ªán: **{lang}**")

        # 5) D·ªãch n·∫øu c·∫ßn
        if lang != "en":
            st.header("3. Translation")
            translator = get_translator(lang)
            with st.spinner("‚è≥ D·ªãch sang English..."):
                for s in segments:
                    try:
                        s["text"] = translator(s["text"])[0]["translation_text"]
                    except:
                        s["text"] = "[L·ªói d·ªãch thu·∫≠t]"

        # 6) Build DataFrame & preprocess
        st.header("4. Build DataFrame & Preprocessing")
        records = []
        for s in segments:
            txt = s["text"].strip()
            records.append({
                "start": s["start"],
                "end":   s["end"],
                "text":  txt,
                "features": processor.prepare_data(txt)
            })
        df = pd.DataFrame(records)
        st.dataframe(df, use_container_width=True)

        # 7) TF-IDF & predict
        st.header("5. Emotion Classification")
        with st.spinner("‚è≥ TF-IDF & SVC predict..."):
            X = tfidf_model.transform(df["text"])
            preds = svc_model.predict(X)
        label_map = {
            "0":"bu·ªìn","1":"vui","2":"y√™u",
            "3":"gi·∫≠n d·ªØ","4":"s·ª£ h√£i","5":"ng·∫°c nhi√™n","6":"ko ch·ª©a c·∫£m x√∫c"
        }
        df["C·∫£m x√∫c"] = pd.Series(preds.astype(str)).map(label_map)
        st.dataframe(df[["start","end","text","C·∫£m x√∫c"]], use_container_width=True)

        # 8) Th·ªëng k√™ & bi·ªÉu ƒë·ªì
        t1 = time.perf_counter()
        elapsed = t1 - t0
        st.success(f"‚úÖ Ho√†n th√†nh trong **{elapsed:.1f} gi√¢y**")

        counts = df["C·∫£m x√∫c"].value_counts()
        fig1, ax1 = plt.subplots()
        explode = [0.1 if v/counts.sum()<0.1 else 0 for v in counts.values]
        ax1.pie(counts.values, labels=counts.index, explode=explode,
                autopct="%1.1f%%", startangle=140, wedgeprops={"linewidth":1,"edgecolor":"white"})
        ax1.axis("equal"); st.pyplot(fig1)

        fig2, ax2 = plt.subplots(figsize=(10,6))
        ax2.bar(counts.index, counts.values)
        ax2.set_xlabel("C·∫£m x√∫c"); ax2.set_ylabel("S·ªë l∆∞·ª£ng"); ax2.set_title("S·ªë l∆∞·ª£ng m·ªói c·∫£m x√∫c")
        st.pyplot(fig2)

        # 9) Download CSV
        st.header("T·∫£i v·ªÅ k·∫øt qu·∫£")
        csv = df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button("üì• T·∫£i CSV", csv,
                           file_name=f"{os.path.splitext(os.path.basename(video_path))[0]}_subtitles.csv",
                           mime="text/csv")

        # 10) Cleanup t·∫°m
        if mode=="T·∫£i l√™n file" and video_path:
            os.remove(video_path)
        if mode=="Nh·∫≠p URL":
            shutil.rmtree("temp_video", ignore_errors=True)
