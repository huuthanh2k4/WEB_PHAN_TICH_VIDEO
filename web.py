import os
import time
import tempfile
import shutil
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import whisper
import joblib
from transformers import pipeline
from yt_dlp import YoutubeDL
from NPL.tien_xu_ly import TienXuLy

# --- Th√™m ffmpeg_static v√†o PATH ƒë·ªÉ Whisper t√¨m ƒë∆∞·ª£c ffmpeg ---
ffmpeg_dir = os.path.join(os.getcwd(), "ffmpeg_static")
ffmpeg_path = os.path.join(ffmpeg_dir, "ffmpeg")
ffprobe_path = os.path.join(ffmpeg_dir, "ffprobe")
if os.path.isfile(ffmpeg_path) and os.path.isfile(ffprobe_path):
    try:
        os.chmod(ffmpeg_path, 0o755)
        os.chmod(ffprobe_path, 0o755)
    except Exception:
        pass
    os.environ["PATH"] = ffmpeg_dir + os.pathsep + os.environ.get("PATH", "")
    os.environ["FFMPEG_BINARY"] = ffmpeg_path


st.set_page_config(page_title="Subtitle & Emotion Analyzer", layout="wide")
st.title("üé¨ Ph√¢n t√≠ch ph·ª• ƒë·ªÅ & c·∫£m x√∫c t·ª´ video")

# --- Utility: download any video URL to MP4 via yt-dlp ---
def download_video(url: str, out_dir: str = "temp_video") -> str:
    os.makedirs(out_dir, exist_ok=True)
    ydl_opts = {
        "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]",
        "outtmpl": os.path.join(out_dir, "%(id)s.%(ext)s"),
        "merge_output_format": "mp4",
        "quiet": True,
    }
    with YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=True)
        return ydl.prepare_filename(info)

# --- Cache heavy resources to speed up reruns ---
@st.cache_resource(show_spinner=False)
def load_whisper_model():
    return whisper.load_model("base")

@st.cache_resource(show_spinner=False)
def load_translator(src_lang: str):
    return pipeline("translation", model=f"Helsinki-NLP/opus-mt-{src_lang}-en")

@st.cache_resource(show_spinner=False)
def load_tfidf_model():
    return joblib.load("TF-IDF6.sav")

@st.cache_resource(show_spinner=False)
def load_svc_model():
    return joblib.load("SVC6.sav")

@st.cache_resource(show_spinner=False)
def load_svc_max():
    return joblib.load("SVC7.sav")

@st.cache_resource(show_spinner=False)
def load_tfidf_model1():
    return joblib.load("TF-IDF7.sav")

# Load models & processor once
whisper_model = load_whisper_model()
processor     = TienXuLy()
tfidf_model6    = load_tfidf_model()
tfidf_model7    = load_tfidf_model1()
svc_model      = load_svc_model()
svc_max       =  load_svc_max()

# --- Sidebar: choose input method ---
st.sidebar.header("1. Ch·ªçn ngu·ªìn video")
mode = st.sidebar.radio("Ch·ªçn:", ("T·∫£i l√™n file", "Nh·∫≠p URL"))


st.sidebar.header("Ch·ªçn model ƒë·ªÉ x·ª≠ l√Ω")
chon_model = st.sidebar.radio(
    "Model:",
    ("ph√¢n lo·∫°i 1 c√≥ 7 lo·∫°i", "ph√¢n lo·∫°i 2 c√≥ 6 lo·∫°i")
)

if chon_model == "ph√¢n lo·∫°i 1 c√≥ 7 lo·∫°i" :
    chon_model = svc_max
    tfidf = tfidf_model7
elif chon_model == "ph√¢n lo·∫°i 2 c√≥ 6 lo·∫°i" :
    chon_model = svc_model
    tfidf = tfidf_model6

video_path = None
if mode == "T·∫£i l√™n file":
    uploaded = st.sidebar.file_uploader("Ch·ªçn video (.mp4/.mov/.avi)", type=["mp4", "mov", "avi"])
    if uploaded:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(uploaded.read())
            video_path = tmp.name
elif mode == "Nh·∫≠p URL":
    url = st.sidebar.text_input("Nh·∫≠p link video (YouTube, TikTok, Vimeo, ...):")
    if url:
        try:
            with st.spinner("‚è≥ ƒêang t·∫£i video..."):
                video_path = download_video(url)
            st.sidebar.success(f"‚úîÔ∏è ƒê√£ t·∫£i v·ªÅ: {os.path.basename(video_path)}")
        except Exception as e:
            st.sidebar.error(f"‚ùå T·∫£i video th·∫•t b·∫°i: {e}")
            st.stop()

if not video_path:
    st.sidebar.warning("Vui l√≤ng cung c·∫•p video ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()
else:
    st.sidebar.success(f"‚úîÔ∏è ƒê√£ ch·ªçn video: {os.path.basename(video_path)}")

# --- Auto-reset khi ng∆∞·ªùi d√πng ch·ªçn video m·ªõi ---
if "last_video" not in st.session_state:
    st.session_state.last_video = None

if video_path and st.session_state.last_video != video_path:
    # X√≥a m·ªçi state c≈© tr·ª´ last_video
    for key in list(st.session_state.keys()):
        if key != "last_video":
            del st.session_state[key]
    st.session_state.last_video = video_path

# --- Start processing ---
t0 = time.perf_counter()

st.header("2. Transcription")
with st.spinner("‚è≥ ƒêang ch·∫°y Whisper transcription..."):
    transcription = whisper_model.transcribe(video_path)
segments = transcription["segments"]
lang = transcription["language"]
st.write(f"üî§ Ph√°t hi·ªán ng√¥n ng·ªØ: **{lang}**")

if lang != "en":
    st.header("3. Translation")
    with st.spinner("‚è≥ ƒêang d·ªãch sang ti·∫øng Anh..."):
        translator = load_translator(lang)
        for seg in segments:
            try:
                seg["ph·ª• ƒë·ªÅ"] = translator(seg["ph·ª• ƒë·ªÅ"])[0]["translation_text"]
            except:
                seg["ph·ª• ƒë·ªÅ"] = "[L·ªói d·ªãch thu·∫≠t]"

st.header("4. Build DataFrame & Preprocessing")
records = []
for seg in segments:
    txt = seg["ph·ª• ƒë·ªÅ"].strip()
    records.append({
        "start":    seg["start"],
        "end":      seg["end"],
        "ph·ª• ƒë·ªÅ":     txt,
        "x·ª≠ l√Ω ph·ª• ƒë·ªÅ cho model": processor.prepare_data(txt)
    })
df = pd.DataFrame(records)
st.dataframe(df, use_container_width=True)

st.header("5. Emotion Classification")
with st.spinner("‚è≥ M√£ ho√° TF-IDF v√† d·ª± ƒëo√°n c·∫£m x√∫c..."):
    X = tfidf.transform(df["x·ª≠ l√Ω ph·ª• ƒë·ªÅ cho model"])
    preds = chon_model.predict(X)
label_map = {
    "0": "bu·ªìn",    "1": "vui",    "2": "y√™u",
    "3": "gi·∫≠n d·ªØ", "4": "s·ª£ h√£i","5": "ng·∫°c nhi√™n",
    "6": "ko ch·ª©a c·∫£m x√∫c"
}
df["C·∫£m x√∫c"] = pd.Series(preds.astype(str)).map(label_map)
st.dataframe(df[["start", "end", "ph·ª• ƒë·ªÅ", "C·∫£m x√∫c"]], use_container_width=True)

t1 = time.perf_counter()
elapsed = t1 - t0
if elapsed < 60:
    st.success(f"‚úÖ Ho√†n th√†nh trong **{elapsed:.2f} gi√¢y**")
else:
    st.success(f"‚úÖ Ho√†n th√†nh trong **{elapsed/60:.2f} ph√∫t**")

st.header("6. Th·ªëng k√™ C·∫£m x√∫c")
counts = df["C·∫£m x√∫c"].value_counts()
fig1, ax1 = plt.subplots()
explode = [0.1 if v/counts.sum() < 0.1 else 0 for v in counts.values]
ax1.pie(counts.values, labels=counts.index, explode=explode,
        autopct="%1.1f%%", startangle=140,
        wedgeprops={"linewidth":1, "edgecolor":"white"})
ax1.axis("equal")
st.pyplot(fig1)

fig2, ax2 = plt.subplots(figsize=(10, 6))
ax2.bar(counts.index, counts.values)
ax2.set_xlabel("C·∫£m x√∫c")
ax2.set_ylabel("S·ªë l∆∞·ª£ng")
ax2.set_title("S·ªë l∆∞·ª£ng m·ªói c·∫£m x√∫c")
st.pyplot(fig2)

st.header("7. T·∫£i v·ªÅ k·∫øt qu·∫£")
csv_data = df.to_csv(index=False, encoding="utf-8-sig")
st.download_button("üì• T·∫£i CSV", data=csv_data,
                   file_name=f"{os.path.splitext(os.path.basename(video_path))[0]}_subtitles.csv",
                   mime="text/csv")

# --- N√∫t reset to√†n b·ªô ƒë·ªÉ ph√¢n t√≠ch video m·ªõi ---
if st.button("üîÑ Ph√¢n t√≠ch video m·ªõi", key="reset_btn"):
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    if os.path.isdir("temp_video"):
        shutil.rmtree("temp_video", ignore_errors=True)
    st.experimental_rerun()

# --- Cleanup file t·∫°m n·∫øu l√† upload ---
if mode == "T·∫£i l√™n file" and video_path:
    os.remove(video_path)
elif mode == "Nh·∫≠p URL" and video_path:
    shutil.rmtree("temp_video", ignore_errors=True)
